<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
  <link rel="alternate icon" type="image/png" href="/img/favicon.ico">
  <title>
    
      Jacobi Decoding |
     
    Blog
  </title>
  
<link rel="stylesheet" href="/css/maoblog.css">

  
<link rel="stylesheet" href="/css/partials/post.css">

  
<link rel="stylesheet" href="/css/partials/comment.css">

  
<link rel="stylesheet" href="/css/partials/search.css">

  
<link rel="stylesheet" href="/css/partials/meta.css">

  
<link rel="stylesheet" href="/css/partials/about.css">

  
<link rel="stylesheet" href="/fontawesome/css/font-awesome.min.css">

  
<link rel="stylesheet" href="/css/zoom.css">

  
<link rel="stylesheet" href="/css/prism.css">

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="/css/math/katex.min.css">

<link rel="stylesheet" href="/css/math/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="Blog" type="application/atom+xml">
</head>


  <body>
    <div class="body-container">
      <div class="body-main">
        <div class="header-wrapper"><div class="header">
  <a class="logo" href="/">Blog</a>
  <ul class="nav">
    
      
        <li><a href="/">Posts</a></li>
      
    
      
        <li><a href="/tags">Tags</a></li>
      
    
      
        <li><a style="cursor: pointer;" onclick="openSearchBar()">Search</a></li>
      
    
      
        <li><a href="/about">About</a></li>
      
    
    <!-- <li class="site-mode">light</i></li> -->
  </ul>
</div>
<div class="search-bar-container">  
    <div class="search-bar">
        <input id="search-input" value="" class="search-input" autofocus placeholder="Search something..." type="text" onblur="hideSearchBar()" oninput="exportSearchContent()">
    </div>
    <div class="search-output">
        <ul class="search-output-list">
            <!-- 结果列表 -->
            <!-- <span style="padding-left: 3px; margin-left: 3px;">无记录</span> -->
            <li class="Searching">
                <div class="content">
                    Searching...
                </div>
            </li>
        </ul>
        <span style="padding-left: 3px; margin-left: 3px; font-size: 13px;"><em>Powered by <span  onclick="goToLink(this)"><a href="/search.xml" class="search-xml li-link">search.xml</a></span></em></span>
    </div>
</div></div>
        <div class="main-wrapper"><main>
  <div class="main-container">
      <div class="post-details">
          
            <div class="post-title">
              <h1>Jacobi Decoding</h1>
            </div>
          
          <div class="post-content">
            <h1 id="jacobi-decoding"><a class="markdownIt-Anchor" href="#jacobi-decoding"></a> Jacobi Decoding</h1>
<p>在神经机器翻译（NMT）中，Transformer 模型已成为主流。然而，虽然 Transformer 在训练阶段可以高度并行化，但在推理阶段却依赖<strong>自回归解码</strong>（autoregressive decoding），即一次生成一个 token，每个新 token 又依赖前面已经生成的 token。这种<strong>顺序依赖</strong>导致推理速度成为瓶颈，特别是在需要低延迟的实际应用中。以往的研究多集中在 <strong>非自回归翻译（NAT）</strong>，它可以一次性并行生成整句翻译。但 NAT 方法往往需要重新设计模型结构、消耗大量训练资源，而且翻译质量通常会有所下降。</p>
<p>这篇 ACL 2023 的论文提出了一条<strong>全新的路径</strong>：与其重新训练模型，不如<strong>改变解码算法本身</strong>，让现有的自回归模型也能“并行解码”。</p>
<img src="https://raw.githubusercontent.com/weikangqi/picgo/main/equations.png" alt="img" style="zoom: 50%;" />
<p>Jacobi Decoding 就是寻求更少的迭代，寻找方程组的解（fixed point）。Jacobi decoding 在生产上，目前还没有相对自回归获得比较大的加速比。可以查考下面的流程：</p>
<img src="https://raw.githubusercontent.com/weikangqi/picgo/main/jacobi-iteration.gif" alt="img" style="zoom: 33%;" />
<p>从这个图可以看到，Jacobi decoding每次迭代更新多个token，每次计算输出步长是M，可以作为一个batch并行的推理，相对单步耗时是增加的，但是对于是访存受限型的来讲，如果accept率可以上升还是又加速效果的。</p>
<ol>
<li>PJ：以句子为单位，每次处理一个句子</li>
<li>PGJ：以字词为单位，每次处理一个字词</li>
<li>HGJ：PGJ 的基础上，增加EOS 字符中途快速退出的兼容</li>
</ol>
<img src="https://raw.githubusercontent.com/weikangqi/picgo/main/image-20250902112750988.png" alt="image-20250902112750988" style="zoom:50%;" />
<h2 id="初始化guess-token"><a class="markdownIt-Anchor" href="#初始化guess-token"></a> 初始化Guess Token</h2>
<p>如果没有特别初始化，默认Guess Token填为&lt;pad&gt;</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">JacobiDecoder</span><span class="token punctuation">(</span>MTDecoder<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> model<span class="token punctuation">,</span> initializer<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>tokenizer<span class="token punctuation">,</span> model<span class="token punctuation">,</span> initializer<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">"jacobi"</span>
        self<span class="token punctuation">.</span>acronym <span class="token operator">=</span> <span class="token string">"j"</span>

    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        input_ids<span class="token punctuation">,</span>
        attention_mask<span class="token punctuation">,</span>
        target_len<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        gold_target<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        init_tensor<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        compute_ddg<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
        logits_preprocessor<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        <span class="token operator">*</span>args<span class="token punctuation">,</span>
        <span class="token operator">**</span>kwargs
    <span class="token punctuation">)</span><span class="token punctuation">:</span>


        <span class="token keyword">if</span> init_tensor <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            init_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>
                <span class="token punctuation">[</span>self<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">]</span> <span class="token operator">*</span> input_ids<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">*</span> max_length<span class="token punctuation">,</span>
                device<span class="token operator">=</span>self<span class="token punctuation">.</span>device<span class="token punctuation">,</span>
            <span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>input_ids<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> max_length<span class="token punctuation">)</span>
        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>is_mbart<span class="token punctuation">:</span>
 			<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>


    <span class="token keyword">def</span> <span class="token function">initialize</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> init_transl<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>initializer <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            init_tensor<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>initializer<span class="token punctuation">.</span>init_translation<span class="token punctuation">(</span>init_transl<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            init_tensor <span class="token operator">=</span> <span class="token boolean">None</span>

        <span class="token keyword">return</span> init_tensor

    <span class="token keyword">def</span> <span class="token function">compute_decode_kwargs</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_ids<span class="token punctuation">,</span> attention_mask<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>

        gold_autoregressive <span class="token operator">=</span> self<span class="token punctuation">.</span>generate_gold_autoregressive<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> attention_mask<span class="token punctuation">)</span>
        init_tensor <span class="token operator">=</span> self<span class="token punctuation">.</span>initialize<span class="token punctuation">(</span>init_transl<span class="token operator">=</span>gold_autoregressive<span class="token punctuation">)</span>
        logits_preprocessor <span class="token operator">=</span> self<span class="token punctuation">.</span>generate_logits_preprocessor<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span>

        <span class="token keyword">return</span> <span class="token punctuation">&#123;</span>
            <span class="token string">"init_tensor"</span><span class="token punctuation">:</span> init_tensor<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">"target_len"</span><span class="token punctuation">:</span> gold_autoregressive<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token string">"gold_target"</span><span class="token punctuation">:</span> gold_autoregressive<span class="token punctuation">,</span>
            <span class="token string">"logits_preprocessor"</span><span class="token punctuation">:</span> logits_preprocessor
        <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

          </div>
          
            <div class="dot-line"></div>
            <div class="post-meta">
              <div class="post-date">
                <i class="fa fa-calendar"></i>&nbsp;&nbsp;<span class="post-date">2025/07/02</span>
              </div>
              <div class="post-tags">
                 
                  
                    <div class="tag-item">
                      <a href="/tags/LLM/"><i class="fa fa-tag"></i>&nbsp;&nbsp;LLM</a>
                    </div>
                  
                    <div class="tag-item">
                      <a href="/tags/%E6%8A%95%E6%9C%BA%E8%A7%A3%E7%A0%81/"><i class="fa fa-tag"></i>&nbsp;&nbsp;投机解码</a>
                    </div>
                  
                
              </div>
            </div>
          
      </div>
  </div>
</main>

<script src="https://giscus.app/client.js"
        data-repo="maodaisuki/hexo-theme-maoblog"
        data-repo-id="R_kgDOKICkkw"
        data-category="Announcements"
        data-category-id="DIC_kwDOKICkk84CZEWg"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="0"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
<!-- 前往 https://giscus.app 获取配置代码 -->


  
<script src="/js/mermaid.min.js"></script>



<script src="/js/zoom/jquery.min.js"></script>


<script src="/js/zoom/bootstrap.min.js"></script>


<script src="/js/zoom/zoom.js"></script>


<script src="/js/maoblog.js"></script>


<script src="/js/prism.js"></script>
</div>
        <div class="footer-wrapper"><footer>
  <div class="footer-container">
    <div class="footer-meta">
      
        <div class="footer-meta-copyright">
          &copy; 2025 mao.
        </div>
      
      
        <div class="footer-meta-licenese">
          Licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC-BY-NC-SA 4.0</a>
        </div>
      
      
        <div class="footer-meta-rss">
          <a href="/atom.xml"><i class="fa fa-rss"></i></a>
        </div>
      
    </div>
  </div>
</footer>
</div>
      </div>
    </div>
  </body>
  <script type="text/javascript">
    var searchXMLPath = "https://weikangqi.github.io" + "/" + "search.xml"
    console.log(searchXMLPath)
  </script>
  
<script src="/js/search/search.js"></script>

</html>